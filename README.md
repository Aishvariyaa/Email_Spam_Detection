
## ğŸ“§ Spam Email Classifier (Binary Classification)  

### ğŸ“Œ Overview  
This project builds a **Spam Email Classifier** that detects whether an email is **Spam or Not Spam** using **machine learning algorithms**. ğŸ“©ğŸš«  

### ğŸ” Key Steps  
âœ… **Dataset Preprocessing:**  
   - Removed **punctuation & special characters** âœ‚ï¸  
   - Converted text to **lowercase** ğŸ”¡  
   - Applied **Tokenization & Lemmatization** using **NLTK** ğŸ“  
   - Transformed text into numerical vectors using **TF-IDF Vectorization** ğŸ”¢  
âœ… **Model Training:**  
   - **Logistic Regression** ğŸ“Š  
   - **Support Vector Machine (SVM)** ğŸ“ˆ  
   - **NaÃ¯ve Bayes Classifier** ğŸ¤–  
âœ… **Model Evaluation:**  
   - **Accuracy, Precision, Recall, F1-Score** for performance comparison ğŸ“Š  

### ğŸ“‚ Project Structure  
```
Spam-Email-Classifier/
â”‚â”€â”€ README.md  # Documentation  
â”‚â”€â”€ spam_classifier.ipynb  # Jupyter Notebook (Model Training & Evaluation)    
```  

### ğŸ”— Dataset Link  
ğŸ“Œ **Dataset Source:** [Spam SMS Dataset](#) 

### ğŸ“Š Dataset  
For this project, we use a **Spam SMS dataset** containing:  

ğŸ“Œ **Features**:  
- **Text Message:** The actual content of the email/SMS  
- **Word Frequency Features:** TF-IDF scores of words  

ğŸ¯ **Target Variable**: **Spam (1) / Not Spam (0)**  

### ğŸ”§ Technologies Used  
ğŸ”¹ Python  
ğŸ”¹ Pandas & NumPy (Data Processing)  
ğŸ”¹ Scikit-learn (ML Models & Evaluation)  
ğŸ”¹ NLTK (Natural Language Processing)  
ğŸ”¹ Matplotlib & Seaborn (Data Visualization)  

### ğŸ“œ How to Run the Project?  
#### 1ï¸âƒ£ Clone the Repository  
```bash
git clone https://github.com/Aishvariyaa/Spam-Email-Classifier.git
cd Spam-Email-Classifier
```  

#### 2ï¸âƒ£ Install Dependencies  
```bash
pip install -r requirements.txt
```

#### 4ï¸âƒ£ Run the Jupyter Notebook  
```bash
jupyter notebook spam_classifier.ipynb
```  

### ğŸ“ˆ Model Performance  
ğŸ“Œ **Model Results Based on Your Provided Data:**  

#### ğŸ”¹ **NaÃ¯ve Bayes Model**  
- **Accuracy:** **100.0%**  
- **Precision:** 1.00  
- **Recall:** 1.00  
- **F1-Score:** 1.00  

#### ğŸ”¹ **Logistic Regression Model**  
- **Accuracy:** **100.0%**  
- **Precision:** 1.00  
- **Recall:** 1.00  
- **F1-Score:** 1.00  

#### ğŸ”¹ **Support Vector Machine (SVM) Model**  
- **Accuracy:** **100.0%**  
- **Precision:** 1.00  
- **Recall:** 1.00  
- **F1-Score:** 1.00  

ğŸ“Œ **Key Observations**  
- All models achieved **100% accuracy, precision, recall, and F1-score**, indicating a **perfect classification** on the test dataset. ğŸ¯  
- This might suggest the dataset is **too clean or too small**, or there could be potential **overfitting** that needs further analysis.  

### ğŸ“Œ Next Steps  
ğŸ”¹ Test on a **larger, real-world dataset** to check for overfitting.  
ğŸ”¹ Experiment with **Deep Learning models (LSTMs)** for enhanced text classification.  
ğŸ”¹ Deploy the model as a **Flask API** for real-time email filtering.  
